<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="noindex, nofollow"><title>GenAI and Image Segmentation to spice up Presentations | Jan's Blog</title>
<meta name=keywords content="GenAI,productivity,presentations"><meta name=description content="I have been a satisfied user of generative image models such as stable diffusion, Midjourney and DALL·E 2 for over one year now. Admittedly, around 2016 or 2017, when the outputs of Generative Adversarial Networks (GANs) looked super pixelated and weird at times1, I did not get the appeal. Especially when compared with discriminative models that were more efficient and performed way better for sentiment classification and so on.
However, like many people, I realized the great potential of generative approaches at the latest after Midjourney V3 and V4 were launched at the end of 2022."><meta name=author content><link rel=canonical href=http://localhost:1313/posts/presentation-workflow/><link crossorigin=anonymous href=/assets/css/stylesheet.4599eadb9eb2ad3d0a8d6827b41a8fda8f2f4af226b63466c09c5fddbc8706b7.css integrity="sha256-RZnq256yrT0KjWgntBqP2o8vSvImtjRmwJxf3byHBrc=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/presentation-workflow/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Jan's Blog (Alt + H)">Jan's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/link-collection/ title="Link Collection"><span>Link Collection</span></a></li><li><a href=http://localhost:1313/posts/ title=Posts><span>Posts</span></a></li><li><a href=http://localhost:1313/publications/ title=Publications><span>Publications</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">GenAI and Image Segmentation to spice up Presentations
<span class=entry-hint title=Draft><svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentcolor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h1><div class=post-meta><span title='2024-02-22 12:00:00 +0000 +0000'>February 22, 2024</span></div></header><figure class=entry-cover><img loading=eager src=http://localhost:1313/slide_with_image.png alt="slide with image"><p>slide with image</p></figure><div class=post-content><p>I have been a satisfied user of generative image models such as stable diffusion, Midjourney and DALL·E 2 for over one year now. Admittedly, around 2016 or 2017, when the outputs of Generative Adversarial Networks (GANs) looked super pixelated and weird at times<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, I did not get the appeal. Especially when compared with discriminative models that were more efficient and performed way better for sentiment classification and so on.</p><p>However, like many people, I realized the great potential of generative approaches at the latest after Midjourney V3 and V4 were launched at the end of 2022.
While I mainly used these models to create images of imaginary landscapes and futuristic cityscapes, I have learned to appreciate them for more productive uses.</p><h2 id=choosing-the-genai-model>Choosing the GenAI model<a hidden class=anchor aria-hidden=true href=#choosing-the-genai-model>#</a></h2><p>While <strong>Midjourney</strong> often provides more aesthetic (cooler) images with very diverse art styles, I found <strong>DALL·E 2</strong> from OpenAI to be a lot more reliable in following the given instructions for my use cases (the difference is smaller with Midjourney V6).
This is doubly important to quickly create images that are supposed to express a very specific idea or concept.
As added benefit, it can, at least semi-reliably, incorporate text into the images .
While it might require a few tries, it generally seems to work.</p><h2 id=example-use-case>Example Use Case:<a hidden class=anchor aria-hidden=true href=#example-use-case>#</a></h2><p>For example, the following images were created with variants of the following prompt. While we can argue about the artistic value, it highlights how slides can be refined with little work, while avoding use of the typical pictograms or powerpoint templates:</p><p><strong>Prompt</strong></p><blockquote><p><em>Create the image of a futuristic insurance building. It has glass walls. In the inside can be seen a large digital brain that represents an AI that enhances the decisions of the firm. The interior should look modern and cozy, as is typical for a modern tech company. Perspective from outside looking in. On the top of the building is a sign that says &ldquo;Super Insurance&rdquo;. Make sure that it is a perspective from outside overlooking the whole building.</em></p></blockquote><p><strong>Generated images</strong><div style=display:flex><img src=futuristic_insurance_building_1.png alt=Paris style=width:50%;margin-right:10px>
<img src=futuristic_insurance_building_2.png alt=Rome style=width:50%></div></p><h2 id=removing-the-background>Removing the background<a hidden class=anchor aria-hidden=true href=#removing-the-background>#</a></h2><p>To effectively use these images in a presentation, we typically want to remove the background.
While this might be trivial for an experienced photoshop user, I never really got into that.
However, I found <strong><a href=https://segment-anything.com/>Segment Anything</a></strong> which <strong>Meta</strong> open sourced recently really works wonders for exactly this use case.
For me, it really opened up a bit more creative space when it comes to giving presentations more visual appeal.
In addition, since it gives so much control over the images, it possibly allows replacing more bullet points with expressive and straight to the point pictures.</p><h3 id=prompting-with-segmentation-in-mind>Prompting with segmentation in mind<a hidden class=anchor aria-hidden=true href=#prompting-with-segmentation-in-mind>#</a></h3><p>It pays off to keep in mind that you want to segment the image later on already when writing the prompt.
Sometimes the task can be simplified drastically by specifying stuff like: <code>XYZ in front of white background</code></p><h3 id=using-segment-anything>Using Segment Anything<a hidden class=anchor aria-hidden=true href=#using-segment-anything>#</a></h3><p>The UI that Meta AI provides for the demo already seems to be sufficient for the use cases I am thinking about.
However, since this demo may not be used for commercial purposes, I hope that a mature web app is created soon.
This <a href=https://huggingface.co/spaces/Xenova/segment-anything-web>hugging face space</a> also provides the model but the usability is comparable yet.
I am assuming that this functionality will be integrated into a variety of web apps that provide image editing services rather soon.</p><p>This image shows the positive (green) and negative (red) markers that you can use to mark the outline of the object.
Due to the pattern recognition embedded into the model, in many cases only few markers are even necessary.</p><div style=text-align:center><img src=segment_anything_workflow.png alt="slide with image" style=width:70%></div><p><strong>Cropped Image on Presentation Slide</strong><div style=text-align:center><img src=slide_with_image.png alt="slide with image" style=width:70%></div></p><h1 id=links>Links<a hidden class=anchor aria-hidden=true href=#links>#</a></h1><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href="https://blog.research.google/2017/04/teaching-machines-to-draw.html?m=1">https://blog.research.google/2017/04/teaching-machines-to-draw.html?m=1</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/genai/>GenAI</a></li><li><a href=http://localhost:1313/tags/productivity/>Productivity</a></li><li><a href=http://localhost:1313/tags/presentations/>Presentations</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Jan's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>