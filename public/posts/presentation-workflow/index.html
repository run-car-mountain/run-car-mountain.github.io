<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>GenAI and Image Segmentation to spice up Presentations | Jan&#39;s Blog </title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="I have been a happy and satisfied user of generative image models such as stable diffusion, midjourney and dalle for over one year now. Admittedly, when the outputs looked pixelated and bad, I did not get the appeal compared to discriminative models that can help with classification tasks.
While I have mainly used these models to create images of imaginary landscapes and futuristic cityscapes, I have learned to appreciate them for more productive uses recently.">
    <meta name="generator" content="Hugo 0.123.1">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    

    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/posts/presentation-workflow/">
    

    <meta property="og:title" content="GenAI and Image Segmentation to spice up Presentations" />
<meta property="og:description" content="I have been a happy and satisfied user of generative image models such as stable diffusion, midjourney and dalle for over one year now. Admittedly, when the outputs looked pixelated and bad, I did not get the appeal compared to discriminative models that can help with classification tasks.
While I have mainly used these models to create images of imaginary landscapes and futuristic cityscapes, I have learned to appreciate them for more productive uses recently." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/posts/presentation-workflow/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-02-21T17:47:52+01:00" />
<meta property="article:modified_time" content="2024-02-21T17:47:52+01:00" />

<meta itemprop="name" content="GenAI and Image Segmentation to spice up Presentations">
<meta itemprop="description" content="I have been a happy and satisfied user of generative image models such as stable diffusion, midjourney and dalle for over one year now. Admittedly, when the outputs looked pixelated and bad, I did not get the appeal compared to discriminative models that can help with classification tasks.
While I have mainly used these models to create images of imaginary landscapes and futuristic cityscapes, I have learned to appreciate them for more productive uses recently."><meta itemprop="datePublished" content="2024-02-21T17:47:52+01:00" />
<meta itemprop="dateModified" content="2024-02-21T17:47:52+01:00" />
<meta itemprop="wordCount" content="432">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="GenAI and Image Segmentation to spice up Presentations"/>
<meta name="twitter:description" content="I have been a happy and satisfied user of generative image models such as stable diffusion, midjourney and dalle for over one year now. Admittedly, when the outputs looked pixelated and bad, I did not get the appeal compared to discriminative models that can help with classification tasks.
While I have mainly used these models to create images of imaginary landscapes and futuristic cityscapes, I have learned to appreciate them for more productive uses recently."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Jan&#39;s Blog 
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/about/" title="About page">
              About
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/link-collection/" title="Link Collection page">
              Link Collection
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/posts/" title="Posts page">
              Posts
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="/publications/" title="Publications page">
              Publications
            </a>
          </li>
          
        </ul>
      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1">GenAI and Image Segmentation to spice up Presentations</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2024-02-21T17:47:52+01:00">February 21, 2024</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p>I have been a happy and satisfied user of generative image models such as stable diffusion, midjourney and dalle for over one year now. Admittedly, when the outputs looked pixelated and bad, I did not get the appeal compared to discriminative models that can help with classification tasks.</p>
<p>While I have mainly used these models to create images of imaginary landscapes and futuristic cityscapes, I have learned to appreciate them for more productive uses recently.</p>
<h2 id="choosing-the-genai-model">Choosing the GenAI model</h2>
<p>While <strong>midjourney</strong> often provides more aesthetic (cooler) images with very diverse art styles, I have found <strong>DALLÂ·E 2</strong> from OpenAI to be a lot more reliable in following the given instructions for my use cases. This is especially important when you want to use it to quickly create images that are supposed to express a very specific idea. As added benefit, it can even semi-reliably incorporate text into the images. While it might require a few tries, it generally seems to work. It remains to be seen if the new V6 release by midjourney can keep up.</p>
<h2 id="example-use-case">Example Use Case:</h2>
<p>For example, the following images were created with variants of the following prompt. While we can argue about the artistic value, it highlights how slides can be refined with little work, while avoding use of the typical pictograms or powerpoint templates:</p>
<p><strong>Prompt</strong>
{% highlight python %}
&ldquo;Create the image of a futuristic insurance building. It has glass walls. In the inside can be seen a large digital brain that represents an AI that enhances the decisions of the firm. The interior should look modern and cozy, as is typical for a modern tech company. Perspective from outside looking in. On the top of the building is a sign that says &lsquo;Super Insurance&rsquo;. Make sure that it is a perspective from outside overlooking the whole building.&rdquo;
{% endhighlight %}</p>
<p><strong>Generated images</strong>
<img src="slide_with_image.png" alt="slide with image" title="Title"></p>
<h2 id="removing-the-background">Removing the background</h2>
<p>To really use these images in a presentation, we would typically want to remove the background. While this might be easy for someone who is experienced in photoshop, I never really got into that.
However, I found <strong>Segment Anything</strong> that <strong>Meta</strong> released recently really works wonders for exactly this use case.
For me, it really opened up a bit more creative space when it comes to working on presentations.</p>
<h3 id="prompting-with-segmentation-in-mind">Prompting with segmentation in mind</h3>
<p>Already when writing the prompt, it pays off to keep in mind that you want to segment the image later on.
Sometimes the task can be simplified drastically by specifying stuff like <code>&quot;XYZ in front of white background&quot;</code> etc.</p>
<h3 id="using-segment-anything">Using Segment Anything</h3>
<p><a href="https://segment-anything.com/">Segment Anything</a></p>
<p><strong>Generated images</strong>

<div style="display: flex;">
    <img src="futuristic_insurance_building_1.png" alt="Paris" style="width: 50%; margin-right: 10px;">
    <img src="futuristic_insurance_building_2.png" alt="Rome" style="width: 50%;">
  </div></p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="http://localhost:1313/" >
    &copy;  Jan's Blog  2024 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
